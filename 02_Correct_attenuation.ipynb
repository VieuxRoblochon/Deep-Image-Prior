{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/VieuxRoblochon/Deep-Image-Prior/blob/master/02_Correct_attenuation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aIfN5aFTdS0E"
      },
      "source": [
        "\n",
        "# Correct reflectivity attenuation\n",
        "\n",
        "In this example the reflectivity attenuation is calculated and then corrected\n",
        "for a polarimetric radar using a Z-PHI method implemented in Py-ART.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pip install arm-pyart"
      ],
      "metadata": {
        "id": "TVowcjbcdngQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "4wFwefK9dS0H"
      },
      "outputs": [],
      "source": [
        "#print(__doc__)\n",
        "\n",
        "# Author: Jonathan J. Helmus (jhelmus@anl.gov)\n",
        "# License: BSD 3 clause\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import pyart\n",
        "import os\n",
        "import glob as glob\n",
        "import datetime as datetime"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "-MUidgtCeYXO",
        "outputId": "c7981702-4925-4784-efe1-17bca9cf669b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount(\"/ShardDrives/\")"
      ],
      "metadata": {
        "id": "zx20bKjuoEix",
        "outputId": "1824be87-2b01-4ec0-a915-25dea278add7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /ShardDrives/; to attempt to forcibly remount, call drive.mount(\"/ShardDrives/\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "folderpath = f'/ShardDrives/MyDrive/Colab Notebooks (1)/USBR_SWE/radar_data_KGJX/KGJX20230322' \n",
        "os.listdir(folderpath)"
      ],
      "metadata": {
        "id": "tfGWjGxgshO7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "akordj3ydS0J",
        "outputId": "557fa7fd-03bd-4eab-aa70-7f4a19981363",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "206 files in directory /ShardDrives/MyDrive/Colab Notebooks (1)/USBR_SWE/radar_data_KGJX/KGJX20230322\n"
          ]
        }
      ],
      "source": [
        "folderpath = f'/ShardDrives/MyDrive/Colab Notebooks (1)/USBR_SWE/radar_data_KGJX/KGJX20230322' \n",
        "files      = os.listdir(folderpath)\n",
        "# Load Level II data file\n",
        "radarsite = 'KGJX'\n",
        "print(f\"{len(files)} files in directory {folderpath}\")\n",
        "\n",
        "file_pattern = os.path.join(folderpath, '*')\n",
        "files = glob.glob(file_pattern)\n",
        "radars = []\n",
        "for file in files:\n",
        "  # Read Level II files using pyart\n",
        "  radar = pyart.io.read_nexrad_archive(file)\n",
        "  radars.append(radar) # Add radar object to the list\n",
        "      # Call the function to plot the figure\n",
        "      #plot_fig(radar, 'SDUS65_N0Q', 0)\n",
        "print(radar.info())\n",
        "# Retrieve dual-polarization moments\n",
        "reflectivity_h = radar.fields['reflectivity_h']['data']\n",
        "reflectivity_v = radar.fields['reflectivity_v']['data']\n",
        "differential_reflectivity = radar.fields['differential_reflectivity']['data']\n",
        "correlation_coefficient = radar.fields['correlation_coefficient']['data']\n",
        "differential_phase = radar.fields['differential_phase']['data']\n",
        "specific_differential_phase = radar.fields['specific_differential_phase']['data']\n",
        "\n",
        "# Process or visualize the dual-polarization moments as needed\n",
        "# For example, you can plot the reflectivity data:\n",
        "display = pyart.graph.RadarDisplay(radar)\n",
        "display.plot('reflectivity_h', title='Reflectivity (Horizontal)')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c-ilbAbVdS0K"
      },
      "outputs": [],
      "source": [
        "#file = pyart.testing.get_test_data(\"sgpcsaprsurcmacI7.c0.20110520.095101.nc\")\n",
        "\n",
        "def corr_radar(radar):\n",
        "    # perform attenuation correction\n",
        "    spec_at, cor_z = pyart.correct.calculate_attenuation(\n",
        "        radar,\n",
        "        0,\n",
        "        refl_field=\"reflectivity\",\n",
        "        ncp_field=None,\n",
        "        rhv_field=\"cross_correlation_ratio\",\n",
        "        phidp_field=\"specific_differential_phase\",\n",
        "    )\n",
        "    radar.add_field(\"specific_attenuation\", spec_at)\n",
        "    radar.add_field(\"corrected_reflectivity_horizontal\", cor_z)\n",
        "\n",
        "    # create the plot\n",
        "    fig = plt.figure(figsize=(15, 5))\n",
        "    ax1 = fig.add_subplot(131)\n",
        "    display = pyart.graph.RadarDisplay(radar)\n",
        "    display.plot(\n",
        "        \"reflectivity_horizontal\",\n",
        "        0,\n",
        "        ax=ax1,\n",
        "        vmin=0,\n",
        "        vmax=60.0,\n",
        "        colorbar_label=\"\",\n",
        "        title=\"Raw Reflectivity\",\n",
        "    )\n",
        "\n",
        "    ax2 = fig.add_subplot(132)\n",
        "    display.plot(\n",
        "        \"specific_attenuation\",\n",
        "        0,\n",
        "        vmin=0,\n",
        "        vmax=1.0,\n",
        "        colorbar_label=\"\",\n",
        "        ax=ax2,\n",
        "        title=\"Specific Attenuation\",\n",
        "    )\n",
        "\n",
        "    ax3 = fig.add_subplot(133)\n",
        "    display = pyart.graph.RadarDisplay(radar)\n",
        "    display.plot(\n",
        "        \"corrected_reflectivity_horizontal\",\n",
        "        0,\n",
        "        vmin=0,\n",
        "        vmax=60.0,\n",
        "        colorbar_label=\"\",\n",
        "        ax=ax3,\n",
        "        title=\"Corrected Reflectivity\",\n",
        "    )\n",
        "\n",
        "    plt.suptitle(\"Attenuation correction using Py-ART\", fontsize=16)\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "scrolled": true,
        "id": "FIXV8LnXdS0J",
        "outputId": "07848201-ee59-4a82-8b13-1bf5039b0203"
      },
      "outputs": [
        {
          "ename": "KeyError",
          "evalue": "'specific_differential_phase'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
            "Cell \u001b[1;32mIn[34], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m radar \u001b[38;5;241m=\u001b[39m pyart\u001b[38;5;241m.\u001b[39mio\u001b[38;5;241m.\u001b[39mread_nexrad_level3(filename\u001b[38;5;241m=\u001b[39mfile, field_name\u001b[38;5;241m=\u001b[39mprod)\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m#print(radar.info())\u001b[39;00m\n\u001b[1;32m---> 20\u001b[0m \u001b[43mcorr_radar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mradar\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m#plot_fig(radar, prod, bbox)\u001b[39;00m\n",
            "Cell \u001b[1;32mIn[32], line 5\u001b[0m, in \u001b[0;36mcorr_radar\u001b[1;34m(radar)\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcorr_radar\u001b[39m(radar):\n\u001b[0;32m      4\u001b[0m     \u001b[38;5;66;03m# perform attenuation correction\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m     spec_at, cor_z \u001b[38;5;241m=\u001b[39m \u001b[43mpyart\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcorrect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_attenuation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mradar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrefl_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mreflectivity\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m        \u001b[49m\u001b[43mncp_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrhv_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcross_correlation_ratio\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[43m        \u001b[49m\u001b[43mphidp_field\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mspecific_differential_phase\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m     radar\u001b[38;5;241m.\u001b[39madd_field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mspecific_attenuation\u001b[39m\u001b[38;5;124m\"\u001b[39m, spec_at)\n\u001b[0;32m     14\u001b[0m     radar\u001b[38;5;241m.\u001b[39madd_field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcorrected_reflectivity_horizontal\u001b[39m\u001b[38;5;124m\"\u001b[39m, cor_z)\n",
            "File \u001b[1;32m~\\miniconda3\\envs\\metpy-ams-2023\\Lib\\site-packages\\pyart\\correct\\attenuation.py:900\u001b[0m, in \u001b[0;36mcalculate_attenuation\u001b[1;34m(radar, z_offset, debug, doc, fzl, gatefilter, rhv_min, ncp_min, a_coef, beta, refl_field, ncp_field, rhv_field, phidp_field, spec_at_field, corr_refl_field)\u001b[0m\n\u001b[0;32m    898\u001b[0m \u001b[38;5;66;03m# Extract fields and parameters from radar\u001b[39;00m\n\u001b[0;32m    899\u001b[0m reflectivity_horizontal \u001b[38;5;241m=\u001b[39m radar\u001b[38;5;241m.\u001b[39mfields[refl_field][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m--> 900\u001b[0m proc_dp_phase_shift \u001b[38;5;241m=\u001b[39m \u001b[43mradar\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfields\u001b[49m\u001b[43m[\u001b[49m\u001b[43mphidp_field\u001b[49m\u001b[43m]\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdata\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m    901\u001b[0m nsweeps \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(radar\u001b[38;5;241m.\u001b[39mnsweeps)\n\u001b[0;32m    903\u001b[0m \u001b[38;5;66;03m# Determine where the reflectivity is valid, mask out bad locations.\u001b[39;00m\n",
            "\u001b[1;31mKeyError\u001b[0m: 'specific_differential_phase'"
          ]
        }
      ],
      "source": [
        "prods = ['SDUS65_N1Q', 'SDUS85_N1K', 'SDUS85_N1X', 'SDUS85_N1C', 'SDUS75_N1A']\n",
        "\n",
        "field_dict = {'SDUS65_N1Q': 'reflectivity',\n",
        "              'SDUS85_N1K': 'differential_phase',\n",
        "              'SDUS85_N1X': 'differential_reflectivity',\n",
        "              'SDUS85_N1C': 'cross_correlation_ratio',\n",
        "              'SDUS75_N1A': 'specific_attenuation'\n",
        "             }\n",
        "\n",
        "# Define area\n",
        "bbox = [-107, 38.4367, -108.5, 39.5]\n",
        "\n",
        "for prod in prods:\n",
        "    folder_path = r'C:\\GIS-RadarWorkspace\\03182023_to_03252023'     #r'C:\\GIS-RadarWorkspace\\Radar_Data'\n",
        "    fpattern = f'KGJT_{prod}GJX_20230322*' #KGJT_SDUS85_N0XGJX_20230322\n",
        "    files = glob.glob(os.path.join(folder_path, fpattern))\n",
        "    for file in files:\n",
        "        radar = pyart.io.read_nexrad_level3(filename=file, field_name=prod)\n",
        "        #print(radar.info())\n",
        "        corr_radar(radar)\n",
        "        #plot_fig(radar, prod, bbox)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "sNhs6iPldS0K",
        "outputId": "baffd32f-75b6-4ec7-fddb-24594630a2bf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['2022-05-01', '2022-05-04', 190.5, 6.3, 0.4], ['2022-05-05', '2022-05-09', 96.52, 4.58, 0.29], ['2022-05-10', '2022-05-14', 22.86, 7.82, 0.4], ['2022-05-15', '2022-05-19', 22.86, 7.82, 0.4], ['2022-05-20', '2022-05-24', 22.86, 7.82, 0.4], ['2022-05-25', '2022-05-29', 22.86, 7.82, 0.4], ['2022-05-30', '2022-06-01', 22.86, 7.82, 0.4]]\n"
          ]
        }
      ],
      "source": [
        "# Period list with non-overlapping date ranges\n",
        "\"\"\"period_list = [['2021-02-02', '2021-02-04', 50.8, 0.1, 0.15],\n",
        " ['2021-02-05', '2021-02-09', 43.18, -4.94, 0.10],\n",
        " ['2021-02-13', '2021-02-17', 35.56, -2.14, 0.08],\n",
        " ['2021-02-18', '2021-02-22', 45.72, -6.66, 0.07],\n",
        " ['2021-02-23', '2021-02-27', 27.94, -8.67, 0.06],\n",
        " ['2021-02-28', '2021-03-04', 45.72, -2.85, 0.08],\n",
        " ['2021-03-05', '2021-03-09', 73.66, -5.96, 0.19],\n",
        " ['2021-03-10', '2021-03-14', 111.76, -3.08, 0.18],\n",
        " ['2021-03-15', '2021-03-19', 60.96, -0.47, 0.13],\n",
        " ['2021-03-20', '2021-03-24', 66.04, -3.15, 0.14],\n",
        " ['2021-03-25', '2021-03-29', 55.88, -3.51, 0.12],\n",
        " ['2021-03-30', '2021-04-02', 68.58, -0.73, 0.16],\n",
        " ['2021-04-03', '2021-04-07', 363.22, -2.01, 0.3],\n",
        " ['2021-04-08', '2021-04-12', 40.64, -5.06, 0.05],\n",
        " ['2021-04-13', '2021-04-17', 111.76, -0.03, 0.28],\n",
        " ['2021-04-18', '2021-04-22', 111.76, -0.03, 0.28],\n",
        " ['2021-04-23', '2021-04-27', 147.32, 2.65, 0.39],\n",
        " ['2021-04-28', '2021-04-30', 137.16, 3.23, 0.21],\n",
        " ['2021-10-01', '2021-10-04', 43.18, -0.16, 0.06],\n",
        " ['2021-10-05', '2021-10-09', 43.18, -0.16, 0.06],\n",
        " ['2021-10-10', '2021-10-14', 43.18, -0.16, 0.06],\n",
        " ['2021-10-15', '2021-10-19', 43.18, -0.16, 0.06],\n",
        " ['2021-10-20', '2021-10-24', 33.02, 2.22, 0.08],\n",
        " ['2021-10-25', '2021-10-29', 38.1, 3.38, 0.03],\n",
        " ['2021-10-30', '2021-11-03', 35.56, 1.84, 0.04],\n",
        " ['2021-11-04', '2021-11-08', 33.02, 3.08, 0.04],\n",
        " ['2021-11-09', '2021-11-13', 40.64, 2.71, 0.05],\n",
        " ['2021-11-14', '2021-11-18', 35.56, 3.56, 0.03],\n",
        " ['2021-11-19', '2021-11-23', 50.8, 2.49, 0.04],\n",
        " ['2021-11-24', '2021-11-28', 30.48, 0.93, 0.03],\n",
        " ['2021-11-29', '2021-12-02', 38.1, -0.16, 0.03],\n",
        " ['2021-12-03', '2021-12-07', 38.1, -1.04, 0.05],\n",
        " ['2021-12-08', '2021-12-12', 55.88, -4.7, 0.07],\n",
        " ['2021-12-13', '2021-12-17', 48.26, -4.18, 0.09],\n",
        " ['2021-12-18', '2021-12-22', 30.48, -3.73, 0.05],\n",
        " ['2021-12-23', '2021-12-27', 86.36, -0.68, 0.09],\n",
        " ['2021-12-28', '2021-12-31', 96.52, -6.97, 0.14],\n",
        " ['2022-01-01', '2022-01-04', 33.02, -3.96, 0.08],\n",
        " ['2022-01-05', '2022-01-09', 25.4, -2.37, 0.05],\n",
        " ['2022-01-10', '2022-01-14', 40.64, 1.37, 0.06],\n",
        " ['2022-01-30', '2022-02-02', 30.48, -4.38, 0.05],\n",
        " ['2022-01-15', '2022-01-19', 78.74, -0.78, 0.12],\n",
        " ['2022-01-20', '2022-01-24', 78.74, -4.55, 0.19],\n",
        " ['2022-01-25', '2022-01-29', 35.56, -4.38, 0.06],\n",
        " ['2022-02-03', '2022-02-07', 43.18, -5.0, 0.05],\n",
        " ['2022-02-08', '2022-02-11', 30.48, -7.33, 0.05],\n",
        " ['2022-02-12', '2022-02-15', 43.18, -1.13, 0.09],\n",
        " ['2022-02-16', '2022-02-20', 60.96, -1.76, 0.09],\n",
        " ['2022-02-21', '2022-02-25', 63.5, -4.5, 0.11],\n",
        " ['2022-02-26', '2022-02-28', 93.98, -3.4, 0.11],\n",
        " ['2022-03-01', '2022-03-05', 109.22, 2.54, 0.19],\n",
        " ['2022-03-06', '2022-03-10', 81.28, -3.16, 0.09],\n",
        " ['2022-03-11', '2022-03-15', 33.02, -8.43, 0.05],\n",
        " ['2022-03-16', '2022-03-20', 91.44, -2.49, 0.2],\n",
        " ['2022-03-21', '2022-03-25', 116.84, -1.58, 0.22],\n",
        " ['2022-03-26', '2022-03-31', 58.42, -2.5, 0.1],\n",
        " ['2022-04-01', '2022-04-05', 68.58, 3.07, 0.12],\n",
        " ['2022-04-06', '2022-04-11', 83.82, 1.32, 0.14],\n",
        " ['2022-04-12', '2022-04-16', 66.04, 0.99, 0.1],\n",
        " ['2022-04-17', '2022-04-21', 96.52, 2.89, 0.24],\n",
        " ['2022-04-22', '2022-04-26', 63.5, -3.27, 0.12],\n",
        " ['2022-04-27', '2022-04-30', 22.86, 2.67, 0.1]]\"\"\"\n",
        "period_list = [['2022-05-01', '2022-05-04', 190.5, 6.3, 0.4],\n",
        " ['2022-05-05', '2022-05-09', 96.52, 4.58, 0.29],\n",
        " ['2022-05-10', '2022-05-14', 22.86, 7.82, 0.4],\n",
        " ['2022-05-15', '2022-05-19', 22.86, 7.82, 0.4],\n",
        " ['2022-05-20', '2022-05-24', 22.86, 7.82, 0.4],\n",
        " ['2022-05-25', '2022-05-29', 22.86, 7.82, 0.4],\n",
        " ['2022-05-30', '2022-06-01', 22.86, 7.82, 0.4]]\n",
        " \n",
        "print(period_list)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def correct_dual_pol_moments(radar):\n",
        "    # Perform attenuation correction\n",
        "    spec_at, cor_z = pyart.correct.calculate_attenuation(\n",
        "        radar,\n",
        "        0,\n",
        "        fzl=8000.0,\n",
        "        gatefilter=None,\n",
        "        rhv_min=0.5,\n",
        "        ncp_min=0.1,\n",
        "        a_coef=0.06,\n",
        "        beta=0.8,\n",
        "        refl_field=\"total_power\",\n",
        "        ncp_field=\"normalized_coherent_power\",\n",
        "        rhv_field=\"cross_correlation_ratio\",\n",
        "        phidp_field=\"differential_phase\",\n",
        "        spec_at_field=\"specific_attenuation\"\n",
        "    )\n",
        "    radar.add_field(\"KDP_corr\", spec_at, replace_existing=True)\n",
        "    radar.add_field(\"DBTH_corr\", cor_z, replace_existing=True)\n",
        "    return radar\n",
        "\n",
        "def replace_reflectivity_and_attenuation(ds, corrected_reflectivity, corrected_attenuation):\n",
        "    # add the corrected variables without replacing the original variables\n",
        "    dims = ('azimuth', 'range')  # using the correct dimensions: azimuth and range\n",
        "    ds['DBTH_corr'] = (dims, corrected_reflectivity)\n",
        "    ds['KDP_corr'] = (dims, corrected_attenuation)\n",
        "\n",
        "    # add attributes to the new fields indicating they are corrected\n",
        "    ds['DBTH_corr'].attrs['description'] = 'corrected reflectivity'\n",
        "    ds['KDP_corr'].attrs['description'] = 'corrected attenuation'\n",
        "\n",
        "    return ds\n",
        "\n",
        "def fix_angle(ds):\n",
        "    ds['time'] = ds.time.load() # Convert time from dask to numpy\n",
        "    angle_dict = xd.util.extract_angle_parameters(ds)\n",
        "    start_ang = 0 # Set consistent start/end values\n",
        "    stop_ang = 360\n",
        "    angle_res = 1.\n",
        "    direction = angle_dict[\"direction\"]\n",
        "    # first find exact duplicates and remove\n",
        "    ds = xd.util.remove_duplicate_rays(ds)\n",
        "    # second reindex according to retrieved parameters\n",
        "    ds = xd.util.reindex_angle(\n",
        "        ds, start_ang, stop_ang, angle_res, direction, method=\"nearest\"\n",
        "    )\n",
        "    ds = ds.expand_dims('volume_time') # Expand for volumes for concatenation\n",
        "    ds['volume_time'] = [ds.time.min('azimuth').values] # results in 'NaT' values in index. # run\n",
        "    return ds\n",
        "\n",
        "def get_dp_moments(fn):\n",
        "    datasets = []\n",
        "    ds = xr.open_dataset(fn, engine='iris', group='sweep_0')\n",
        "    ds0 = fix_angle(ds)\n",
        "    droplist = ['time', 'VRADH', 'WRADH', 'sweep_mode', 'sweep_number', 'prt_mode', 'follow_mode', 'sweep_fixed_angle']\n",
        "    ds0_drop = ds0.drop_vars(droplist , errors='ignore')\n",
        "    # fix volume_time\n",
        "    #ds0_drop = fix_time_index(ds0_drop, fns[:])\n",
        "    #ds0_drop = fix_time_index1800(ds0_drop, fns[:]) \n",
        "    #ds0_drop = assign_int64time_units_attrs(ds0_drop)\n",
        "    #ref_datetime = np.datetime64('1800-01-01')\n",
        "    #da['volume_time'] = ( (da['volume_time'] - ref_datetime) / np.timedelta64(1, 'h'))\n",
        "    #ds0_drop = add_timezone_to_datetime(ds0_drop)\n",
        "    #ds0_drop = fillna_dataset(ds0_drop)\n",
        "    return ds0_drop\n",
        "\n",
        "def reindex_time_delta_xarray(data, column_name, time_delta):\n",
        "    # Get the length of the dataset\n",
        "    length = len(data[column_name])\n",
        "\n",
        "    # Create a new monotonically increasing datetime index\n",
        "    start_time = pd.to_datetime(data[column_name].values[0].astype('datetime64[ns]'))\n",
        "    new_index = pd.date_range(start_time, periods=length, freq=time_delta)\n",
        "\n",
        "    # Update the 'volume_time' coordinate\n",
        "    data = data.assign_coords({column_name: new_index})\n",
        "\n",
        "    return data\n",
        "\n",
        "def resample_to_hourly(ds):\n",
        "    ds_hourly = ds.resample(volume_time='1H').mean()\n",
        "    return ds_hourly\n",
        "\n",
        "def xarray_fill_nan(da):\n",
        "    duh = da.fillna(0)\n",
        "    # check if null\n",
        "    return duh\n",
        "\n",
        "def get_radar_objects(fn):\n",
        "        radar = pyart.io.read_sigmet(fn)\n",
        "        return radar\n",
        "\n",
        "def zarr_archive(ds, name):\n",
        "    path = r'C:\\Users\\baxter.vieux\\SnowQ_ML\\notebooks\\zarr_archive_TILT3_CORR\\{}.zarr'.format(name)\n",
        "    ds.to_zarr(path, mode='w')\n",
        "    return path\n",
        "\n",
        "data_path = r'C:\\Users\\baxter.vieux\\snow\\KALA'\n",
        "\n",
        "for period in period_list:\n",
        "    start_date, end_date, lat, lon, height = period\n",
        "    start_dt = datetime.datetime.strptime(start_date, '%Y-%m-%d')\n",
        "    end_dt = datetime.datetime.strptime(end_date, '%Y-%m-%d')\n",
        "    delta = datetime.timedelta(days=1)\n",
        "    fns = []\n",
        "    print(f'Processing period: {start_date} to {end_date}')\n",
        "    \n",
        "    # Store the original start date for the current period\n",
        "    original_start_dt = start_dt\n",
        "    \n",
        "    while start_dt <= end_dt:\n",
        "        ymd = start_dt.strftime('%Y%m%d')\n",
        "        ym = start_dt.strftime('%Y%m')\n",
        "        day_path = os.path.join(data_path, ym, ymd)\n",
        "        day_glob = os.path.join(day_path, '*.*') \n",
        "        current_fns = get_fns_start_date_to_end_date(day_glob, start_dt.strftime('%Y%m%d'), end_dt.strftime('%Y%m%d'))\n",
        "        try:\n",
        "            files = sorted(glob.glob(day_glob))\n",
        "        except:\n",
        "            start_dt += delta\n",
        "            continue\n",
        "            \n",
        "        day_complete = False  # Adding this flag to track if we should move to the next day\n",
        "        for file in files:\n",
        "            try:\n",
        "                current_fns = get_fns_start_date_to_end_date(day_glob, start_dt.strftime('%Y%m%d'), end_dt.strftime('%Y%m%d'))\n",
        "                if len(current_fns) > 0:\n",
        "                    fns.extend(current_fns)\n",
        "                    #print(f' for start_dt: {start_dt} to end_dt: {end_dt} len(fns): {len(fns)}')\n",
        "                    day_complete = True  # We found files for this day, so we should move to the next day\n",
        "            except:\n",
        "                print(f\"Error: Incomplete file or missing file: {file}\")\n",
        "\n",
        "            if day_complete:  # If we found files for the day, move to the next day\n",
        "                break  # Break out of the 'for file in files' loop after processing files for the current day\n",
        "                \n",
        "        #print(f'for day {start_dt} current_fns {len(current_fns)} first {current_fns[0]} last {current_fns[-1]}')\n",
        "        start_dt += delta\n",
        "        \n",
        "    if len(fns) > 0:\n",
        "        _first = datetime.datetime.strptime(os.path.basename(fns[0])[0:6], '%y%m%d').strftime('%Y%m%d')\n",
        "        _last = datetime.datetime.strptime(os.path.basename(fns[-1])[0:6], '%y%m%d').strftime('%Y%m%d')\n",
        "        print(f'Converting {len(fns)} RAW files from: {_first} to: {_last}')\n",
        "\n",
        "        # Initialize an empty list to store xarrays\n",
        "        ds0_corr_list = []\n",
        "        for fn in fns:\n",
        "            try:\n",
        "                ds0_drop = get_dp_moments(fn)\n",
        "                ds0_drop = ds0_drop.squeeze()\n",
        "                radar    = get_radar_objects(fn)\n",
        "\n",
        "                corr_radar = correct_dual_pol_moments(radar)\n",
        "\n",
        "                #corrected_reflectivity = corr_radar.fields['corrected_reflectivity_horizontal']['data']\n",
        "                #corrected_attenuation = corr_radar.fields['corrected_specific_attenuation']['data']\n",
        "                corrected_reflectivity = corr_radar.fields['DBTH_corr']['data']\n",
        "                corrected_attenuation = corr_radar.fields['KDP_corr']['data']\n",
        "\n",
        "                ds0_corr = [\n",
        "                    replace_reflectivity_and_attenuation(\n",
        "                        ds0_drop,\n",
        "                        corrected_reflectivity,\n",
        "                        corrected_attenuation\n",
        "                    )\n",
        "                ]\n",
        "                ds0_corr_list.append(ds0_corr[0])\n",
        "            except EOFError:\n",
        "                print(f\"Warning: Unexpected file end or corrupt file detected in {fn}. Skipping this file.\")\n",
        "                continue\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing file {fn}: {e}\")\n",
        "                continue\n",
        "\n",
        "        ds0_corr_combined = xr.concat(ds0_corr_list, dim=\"volume_time\")\n",
        "        ts_delta = pd.to_timedelta('7 minutes 28 seconds')\n",
        "        ds0_corr_combined = ds0_corr_combined.dropna(dim='volume_time', subset=['volume_time'])\n",
        "        ds0_corr_combined = reindex_time_delta_xarray(ds0_corr_combined, 'volume_time', ts_delta)\n",
        "\n",
        "        ds0_corr_combined = reindex_time_delta_xarray(ds0_corr_combined, 'volume_time', ts_delta)\n",
        "        ds0_corr_combined['DBTH_corr'] = xarray_fill_nan(ds0_corr_combined['DBTH_corr'])\n",
        "        ds0_corr_combined['KDP_corr'] = xarray_fill_nan(ds0_corr_combined['KDP_corr'])\n",
        "\n",
        "        ds0_corr_combined_hourly = resample_to_hourly(ds0_corr_combined)\n",
        "        # Convert DataArray back to Dataset\n",
        "        ds0_corr_combined_hourly = ds0_corr_combined_hourly\n",
        "\n",
        "        print(ds0_corr_combined_hourly.info)\n",
        "        \n",
        "        # Save the aggregated dataset to zarr\n",
        "        z_path = zarr_archive(ds0_corr_combined_hourly, f\"data_{_first}_{_last}\")\n",
        "\n",
        "        z_store = zarr.open(z_path, mode='r')\n",
        "        print(f\"saved to: {z_path} \\n with info: {z_store.info}\\n\")\n",
        "\n",
        "        start_dt = original_start_dt\n",
        " "
      ],
      "metadata": {
        "id": "5fivEk0Ch6ux",
        "outputId": "da120069-ca2d-47a4-b3a3-9cda2e5f907e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 236
        }
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-5aed867ec827>\u001b[0m in \u001b[0;36m<cell line: 100>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    100\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mperiod\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mperiod_list\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m     \u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlon\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mheight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mperiod\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 102\u001b[0;31m     \u001b[0mstart_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    103\u001b[0m     \u001b[0mend_dt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrptime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mend_date\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'%Y-%m-%d'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    104\u001b[0m     \u001b[0mdelta\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimedelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdays\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.0"
    },
    "colab": {
      "provenance": [],
      "name": "02 Correct_attenuation.ipynb",
      "gpuType": "T4",
      "include_colab_link": true
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}